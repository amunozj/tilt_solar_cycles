{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import scipy.stats as st\n",
    "from scipy.stats import (vonmises_line, norm, t, cauchy, lognorm, fisk, skewnorm, exponweib, genlogistic, logistic, laplace)\n",
    "import hdbscan\n",
    "import seaborn as sns\n",
    "import colorcet as cc\n",
    "import astropy.units as u\n",
    "import xarray as xr\n",
    "from sunpy.visualization.colormaps import cm\n",
    "import zarr\n",
    "import sunpy.map\n",
    "from sunpy.coordinates import HeliographicCarrington\n",
    "from astropy.coordinates import SkyCoord\n",
    "from sunpy.map.header_helper import make_heliographic_header\n",
    "from sunpy.coordinates import frames\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "import random\n",
    "\n",
    "import glob\n",
    "import os\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define colors an colormaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Color definitions\n",
    "ClrS = (0.74, 0.00, 0.00)\n",
    "ClrN = (0.20, 0.56, 1.00)\n",
    "\n",
    "Clr = [(0.00, 0.00, 0.00),\n",
    "      (0.31, 0.24, 0.00),\n",
    "      (0.43, 0.16, 0.49),\n",
    "      (0.32, 0.70, 0.30),\n",
    "      (0.45, 0.70, 0.90),\n",
    "      (1.00, 0.82, 0.67)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data, add date, Calibrate flux for MDI using 0.8 factor, and apply 3x10^21 Mx cuttoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flux Cutoff in Maxwells\n",
    "fCutoff = 3e21\n",
    "\n",
    "KPVT = pd.read_csv('data/output/BARD_1976-1993_KPVT_tilts.csv')\n",
    "KPVT = KPVT.loc[KPVT['BMRFlux']>=fCutoff,:]\n",
    "KPVT['Date'] = pd.to_datetime(dict(year=KPVT.Year, month=KPVT.Month, day=KPVT.Day, hour=KPVT.Hour, minute=KPVT.Minute))\n",
    "KPVT['Instrument'] = 'KPVT'\n",
    "\n",
    "SPMG = pd.read_csv('data/output/BARD_1992-1999_SPMG_tilts.csv')\n",
    "SPMG = SPMG.loc[SPMG['BMRFlux']>=fCutoff,:]\n",
    "SPMG['Date'] = pd.to_datetime(dict(year=SPMG.Year, month=SPMG.Month, day=SPMG.Day, hour=SPMG.Hour, minute=SPMG.Minute))\n",
    "SPMG['Instrument'] = 'SPMG'\n",
    "SPMG['BMRLabel'] = SPMG['BMRLabel'] + np.max(KPVT['BMRLabel'])\n",
    "\n",
    "MDIcalibration = 0.8\n",
    "MDI = pd.read_csv('data/output/BARD_1996-2010_MDI_tilts.csv')\n",
    "MDI.loc[:, ['PFlux', 'NFlux', 'BMRFlux']] *= MDIcalibration\n",
    "MDI = MDI.loc[MDI['BMRFlux']>=fCutoff,:]\n",
    "MDI['Date'] = pd.to_datetime(dict(year=MDI.Year, month=MDI.Month, day=MDI.Day, hour=MDI.Hour, minute=MDI.Minute))\n",
    "MDI['Instrument'] = 'MDI'\n",
    "MDI['BMRLabel'] = MDI['BMRLabel'] + np.max(SPMG['BMRLabel'])\n",
    "\n",
    "HMI = pd.read_csv('data/output/BARD_2010-2016_HMI_tilts.csv')\n",
    "HMI = HMI.loc[HMI['BMRFlux']>=fCutoff,:]\n",
    "HMI['Date'] = pd.to_datetime(dict(year=HMI.Year, month=HMI.Month, day=HMI.Day, hour=HMI.Hour, minute=HMI.Minute))\n",
    "HMI['Instrument'] = 'HMI'\n",
    "HMI['BMRLabel'] = HMI['BMRLabel'] + np.max(MDI['BMRLabel'])\n",
    "\n",
    "print(np.max(HMI['BMRLongitude']), np.min(HMI['BMRLongitude']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HMI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove overlaps between missions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KPVT = KPVT.loc[KPVT['Date']<np.min(SPMG['Date']),:]\n",
    "SPMG = SPMG.loc[SPMG['Date']<np.min(MDI['Date']),:]\n",
    "MDI = MDI.loc[MDI['Date']<np.min(HMI['Date']),:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate all instruments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allMag = pd.concat([KPVT, SPMG, MDI, HMI], ignore_index=True).drop(labels=['ReferenceDay', 'Flux_cut'], axis=1).replace(np.nan, False).sort_values(by = ['Date']).reset_index(drop = True)\n",
    "allMag.to_csv('data/output/BARD_1976-2016_Merge_tilts.csv', index=False)\n",
    "\n",
    "allMag['pltSize'] = (np.sqrt(allMag['BMRFlux']/1e21))\n",
    "allMag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in allMag.BMRLabel:\n",
    "    df_k = pd.DataFrame((allMag.BMRLabel==k))*1\n",
    "    \n",
    "allMag[allMag.BMRLabel==247].index[1]\n",
    "#allMag.drop(135,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in allMag.BMRLabel:\n",
    "    df_k = (allMag.BMRLabel==k)*1\n",
    "    suma = df_k.sum()#[0]\n",
    "    if suma > 1:\n",
    "        index_1 = allMag[allMag.BMRLabel==k].index[1]\n",
    "        allMag = allMag.drop(index_1, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(allMag.BMRLabel)\n",
    "counter = 0\n",
    "for k in allMag.BMRLabel:\n",
    "    df_k = (allMag.BMRLabel==k)*1\n",
    "    suma = df_k.sum()#[0]\n",
    "    if suma > 1:\n",
    "        counter +=1\n",
    "        print('Problema en BMRLabel ', k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allMag = allMag.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allMag.loc[allMag['BMRLongitude']<0, 'BMRLongitude'] = allMag.loc[allMag['BMRLongitude']<0, 'BMRLongitude']+360"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size definitions\n",
    "dpi = 300\n",
    "pxx = 1600  # Horizontal size of each panel\n",
    "pxy = 500  # Vertical size of each panel\n",
    "\n",
    "nph = 5     # Number of horizontal panels\n",
    "npv = 6     # Number of vertical panels \n",
    "\n",
    "# Padding\n",
    "padv  = 0  #Vertical padding in pixels\n",
    "padv2 = 0  #Vertical padding in pixels between panels\n",
    "padh  = 0 #Horizontal padding in pixels at the edge of the figure\n",
    "padh2 = 0  #Horizontal padding in pixels between panels\n",
    "\n",
    "# Figure sizes in pixels\n",
    "fszv = (npv*pxy + 2*padv + (npv-1)*padv2 )      #Vertical size of figure in pixels\n",
    "fszh = (nph*pxx + 2*padh + (nph-1)*padh2 )      #Horizontal size of figure in pixels\n",
    "\n",
    "# Conversion to relative units\n",
    "ppxx   = pxx/fszh      # Horizontal size of each panel in relative units\n",
    "ppxy   = pxy/fszv      # Vertical size of each panel in relative units\n",
    "ppadv  = padv/fszv     #Vertical padding in relative units\n",
    "ppadv2 = padv2/fszv    #Vertical padding in relative units\n",
    "ppadh  = padh/fszh     #Horizontal padding the edge of the figure in relative units\n",
    "ppadh2 = padh2/fszh    #Horizontal padding between panels in relative units\n",
    "\n",
    "\n",
    "## Start Figure\n",
    "fig = plt.figure(figsize=(fszh/dpi,fszv/dpi), dpi = dpi)\n",
    "\n",
    "ax1 = fig.add_axes([ppadh, ppadv, ppxx, ppxy])\n",
    "\n",
    "size = (np.sqrt(KPVT['BMRFlux']/1e21))\n",
    "ax1.scatter(KPVT['Date'], KPVT['BMRLatitude'], s=size, alpha=0.4, ec='None', label='KPVT/512')\n",
    "\n",
    "\n",
    "size = (np.sqrt(SPMG['BMRFlux']/1e21))\n",
    "ax1.scatter(SPMG['Date'], SPMG['BMRLatitude'], s=size, alpha=0.4, ec='None', label='KPVT/SPMG')\n",
    "\n",
    "\n",
    "size = (np.sqrt(MDI['BMRFlux']/1e21))\n",
    "ax1.scatter(MDI['Date'], MDI['BMRLatitude'], s=size, alpha=0.4, ec='None', label='SOHO/MDI')\n",
    "\n",
    "\n",
    "size = (np.sqrt(HMI['BMRFlux']/1e21))\n",
    "ax1.scatter(HMI['Date'], HMI['BMRLatitude'], s=size, alpha=0.4, ec='None', label='SDO/HMI')\n",
    "\n",
    "\n",
    "size = (np.sqrt(allMag['BMRFlux']/1e21))\n",
    "mask = allMag['AntiHale']\n",
    "ax1.scatter(allMag.loc[mask,'Date'], allMag.loc[mask,'BMRLatitude'], s=size[mask], alpha=1,fc='k', ec='None')\n",
    "\n",
    "\n",
    "ax1.set_ylim([-45, 45])\n",
    "ax1.set_ylabel('Latitude (Â°)')\n",
    "ax1.set_xlabel('Year')\n",
    "ax1.legend(frameon=False, ncol=4, loc='upper center', bbox_to_anchor=(0.475, 1.2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BMR Dipole moment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allMag['BMRColatitude'] = (90 - allMag.BMRLatitude) * np.pi/180\n",
    "allMag['PColatitude'] = (90 - allMag.PLatitude) * np.pi/180\n",
    "allMag['NColatitude'] = (90 - allMag.NLatitude) * np.pi/180\n",
    "\n",
    "R_sun = 6.96 * 10e8 * 10e2  # cm\n",
    "allMag['D_bmr'] = (3/(4*np.pi)) * allMag.BMRFlux * (np.cos(allMag.PColatitude) - np.cos(allMag.NColatitude)) / R_sun**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbins = np.arange(-90, 90, 2)\n",
    "x = np.linspace(-90, 90, 100)\n",
    "\n",
    "# Size definitions\n",
    "dpi = 400\n",
    "pxx = 600  # Horizontal size of each panel\n",
    "pxy = 500  # Vertical size of each panel\n",
    "\n",
    "nph = 5     # Number of horizontal panels\n",
    "npv = 6     # Number of vertical panels \n",
    "\n",
    "# Padding\n",
    "padv  = 0  #Vertical padding in pixels\n",
    "padv2 = 0  #Vertical padding in pixels between panels\n",
    "padh  = 0 #Horizontal padding in pixels at the edge of the figure\n",
    "padh2 = 0  #Horizontal padding in pixels between panels\n",
    "\n",
    "# Figure sizes in pixels\n",
    "fszv = (npv*pxy + 2*padv + (npv-1)*padv2 )      #Vertical size of figure in pixels\n",
    "fszh = (nph*pxx + 2*padh + (nph-1)*padh2 )      #Horizontal size of figure in pixels\n",
    "\n",
    "# Conversion to relative units\n",
    "ppxx   = pxx/fszh      # Horizontal size of each panel in relative units\n",
    "ppxy   = pxy/fszv      # Vertical size of each panel in relative units\n",
    "ppadv  = padv/fszv     #Vertical padding in relative units\n",
    "ppadv2 = padv2/fszv    #Vertical padding in relative units\n",
    "ppadh  = padh/fszh     #Horizontal padding the edge of the figure in relative units\n",
    "ppadh2 = padh2/fszh    #Horizontal padding between panels in relative units\n",
    "\n",
    "\n",
    "# Combine hemispheres \n",
    "\n",
    "\n",
    "## Start Figure\n",
    "fig = plt.figure(figsize=(fszh/dpi,fszv/dpi), dpi = dpi)\n",
    "\n",
    "ax1 = fig.add_axes([ppadh, ppadv, 4*ppxx, ppxy])\n",
    "\n",
    "size = (np.sqrt(allMag['BMRFlux']/1e21))\n",
    "\n",
    "\n",
    "for cyc in np.arange(21,25):\n",
    "\n",
    "    mask = np.logical_or(allMag[f'Cycle{str(cyc)}n'],allMag[f'Cycle{str(cyc)}s'])\n",
    "\n",
    "    \n",
    "\n",
    "    if cyc%2 == 0:\n",
    "\n",
    "        maskp = np.logical_and(mask, allMag['D_bmr']>0)\n",
    "        ax1.scatter(allMag.loc[maskp,'Date'], allMag.loc[maskp,'BMRLatitude'], s=size[maskp], alpha=0.4, ec='None', c='r')\n",
    "\n",
    "        maskn = np.logical_and(mask, allMag['D_bmr']<0)\n",
    "        ax1.scatter(allMag.loc[maskn,'Date'], allMag.loc[maskn,'BMRLatitude'], s=size[maskn], alpha=0.4, ec='None', c='b')\n",
    "\n",
    "    else:\n",
    "\n",
    "        maskn = np.logical_and(mask, allMag['D_bmr']<0)\n",
    "        ax1.scatter(allMag.loc[maskn,'Date'], allMag.loc[maskn,'BMRLatitude'], s=size[maskn], alpha=0.4, ec='None', c='b')        \n",
    "\n",
    "        maskp = np.logical_and(mask, allMag['D_bmr']>0)\n",
    "        ax1.scatter(allMag.loc[maskp,'Date'], allMag.loc[maskp,'BMRLatitude'], s=size[maskp], alpha=0.4, ec='None', c='r')\n",
    "\n",
    "    print(cyc, np.sum(allMag.loc[maskp, 'D_bmr']), np.sum(allMag.loc[maskn, 'D_bmr']))\n",
    "\n",
    "\n",
    "\n",
    "ax1.set_ylim([-45, 45])\n",
    "ax1.set_ylabel('Latitude (Â°)')\n",
    "ax1.set_xlabel('Year')\n",
    "# ax1.legend(frameon=False, ncol=5, loc='upper center', bbox_to_anchor=(0.475, 1.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove spotless days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allMag = allMag.loc[np.isfinite(allMag[\"BMRLatitude\"]), :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Active longitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference day\n",
    "# time_0 = '1970-01-01 00:00:00'\n",
    "\n",
    "time_0 = pd.to_datetime(0)\n",
    "ref_day = (allMag['Date'] - time_0)\n",
    "\n",
    "for i in range(len(ref_day)):\n",
    "    ref_day[i] = ref_day[i].days\n",
    "\n",
    "allMag['ReferenceDay'] = ref_day\n",
    "ref_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diferential rotation\n",
    "\n",
    "def dif_rotation(lat, remove_carrington=False):\n",
    "    A = 14.113463 *u.deg / u.d             # degrees/days\n",
    "    B = -1.6979719 *u.deg / u.d            # degrees/days\n",
    "    C = -1.787 *u.deg / u.d            # degrees/days\n",
    "    c_r = 13.721173 *u.deg / u.d      # degrees/days\n",
    "\n",
    "    if remove_carrington:\n",
    "        return (A + B * np.sin(lat)**2 + C * np.sin(lat)**4) - c_r\n",
    "    else:\n",
    "        return (A + B * np.sin(lat)**2 + C * np.sin(lat)**4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dif_rotation(26*u.deg, remove_carrington=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allMag[\"DRot\"] = dif_rotation(allMag[\"BMRLatitude\"].to_numpy()*u.deg, remove_carrington=True) #- 13.194485832888454 *u.deg / u.d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(allMag[\"BMRLatitude\"], allMag[\"DRot\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distancia para una regiÃ³n\n",
    "# https://www.movable-type.co.uk/scripts/latlong.html\n",
    "\n",
    "def reg_distance(all_mag, region):\n",
    "    # https://www.movable-type.co.uk/scripts/latlong.html\n",
    "    \n",
    "    lon = region['BMRLongitude']*u.deg\n",
    "    lat = region['BMRLatitude']*u.deg\n",
    "    ref_day = region['Date']\n",
    "\n",
    "    rotation = dif_rotation(lat)\n",
    "    \n",
    "    bmr_latitude = all_mag['BMRLatitude'].values *u.deg\n",
    "    bmr_longitude = all_mag['BMRLongitude'].values *u.deg\n",
    "\n",
    "    rotation_diff = np.abs(dif_rotation(bmr_latitude) - rotation)\n",
    "\n",
    "    time_diff = (((ref_day - all_mag['Date']).dt.total_seconds().values*u.s).to(u.d)).value\n",
    "    corrected_longitude = bmr_longitude - rotation_diff * time_diff * u.d\n",
    "\n",
    "\n",
    "    # distance\n",
    "\n",
    "    R_sun = 695700 *u.km  # sun radius (km)\n",
    "    delta_lon = corrected_longitude - lon\n",
    "\n",
    "    delta_lat = (bmr_latitude - lat)\n",
    "    harversin = np.power(np.sin(delta_lat/2), 2) + np.cos(lat)*np.cos(bmr_latitude)*np.power(np.sin(delta_lon/2), 2)\n",
    "    delta_sigma = 2*np.arctan2(np.sqrt(harversin), np.sqrt(1-harversin))\n",
    "\n",
    "    distance = delta_sigma.to(u.deg) # *R_sun\n",
    "\n",
    "    delta_lon = delta_lon - (np.abs(delta_lon)//(360*u.deg)*np.sign(delta_lon.value))*360*u.deg\n",
    "    delta_lon[delta_lon < -180*u.deg] = 360*u.deg+delta_lon[delta_lon < -180*u.deg]\n",
    "    delta_lon[delta_lon > 180*u.deg] = -(360*u.deg-delta_lon[delta_lon > 180*u.deg])\n",
    "\n",
    "    return (distance, np.abs(time_diff), np.abs(delta_lat), np.abs(delta_lon))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Symmetry test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pick two random regions\n",
    "inx1 = np.random.randint(0, allMag.shape[0])\n",
    "inx2 = np.random.randint(0, allMag.shape[0])\n",
    "\n",
    "print(allMag.iloc[[inx1], 0:].loc[:,['BMRLatitude', 'BMRLongitude', 'Date']])\n",
    "print(allMag.iloc[[inx2], 0:].loc[:,['BMRLatitude', 'BMRLongitude', 'Date']])\n",
    "\n",
    "print(reg_distance(allMag.iloc[[inx2], 0:], allMag.iloc[inx1, 0:]))\n",
    "print(reg_distance(allMag.iloc[[inx1], 0:], allMag.iloc[inx2, 0:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pick first two regions\n",
    "inx1 = 1\n",
    "inx2 = 0\n",
    "\n",
    "print(allMag.iloc[[inx1], 0:].loc[:,['BMRLatitude', 'BMRLongitude', 'Date']])\n",
    "print(allMag.iloc[[inx2], 0:].loc[:,['BMRLatitude', 'BMRLongitude', 'Date']])\n",
    "\n",
    "print(reg_distance(allMag.iloc[[inx2], 0:], allMag.iloc[inx1, 0:]))\n",
    "print(reg_distance(allMag.iloc[[inx1], 0:], allMag.iloc[inx2, 0:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test matrix with only a small subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortMag = allMag.iloc[range(4),:].copy()\n",
    "\n",
    "distance_matrix = np.zeros((len(shortMag), len(shortMag)))\n",
    "time_diff_matrix = np.zeros((len(shortMag), len(shortMag)))\n",
    "\n",
    "for k in range(len(shortMag)):\n",
    "    region = shortMag.iloc[k,0:]\n",
    "    distance = reg_distance(shortMag, region)#.to_numpy()\n",
    "    distance_matrix[k,:] = distance[0]\n",
    "    time_diff_matrix[k,:] = distance[1]\n",
    "\n",
    "distance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_matrix.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(distance_matrix - distance_matrix.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_matrix = np.zeros((len(allMag), len(allMag)))\n",
    "time_diff_matrix = np.zeros((len(allMag), len(allMag)))\n",
    "lat_diff_matrix = np.zeros((len(allMag), len(allMag)))\n",
    "lon_diff_matrix = np.zeros((len(allMag), len(allMag)))\n",
    "\n",
    "for k in range(len(allMag)):\n",
    "    region = allMag.iloc[k,0:]\n",
    "    distance = reg_distance(allMag, region)#.to_numpy()\n",
    "    distance_matrix[k,:] = distance[0]\n",
    "    time_diff_matrix[k,:] = distance[1]\n",
    "    lat_diff_matrix[k,:] = distance[2]\n",
    "    lon_diff_matrix[k,:] = distance[3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(distance_matrix - distance_matrix.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(distance_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.pcolormesh(distance_matrix, cmap='Reds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Combine time and distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize distance using mean\n",
    "distance_matrix_norm = distance_matrix/np.median(distance_matrix)\n",
    "\n",
    "# Normalize time difference using mean\n",
    "time_diff_matrix_norm = time_diff_matrix/np.median(time_diff_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Establecer el tamaÃ±o de la figura\n",
    "# plt.figure(figsize=(6, 6))  \n",
    "\n",
    "# # Crear la visualizaciÃ³n de la matriz utilizando pcolormesh\n",
    "# plt.pcolormesh(distance_matrix_norm, cmap='Reds')\n",
    "# plt.colorbar()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establecer el tamaÃ±o de la figura\n",
    "plt.figure(figsize=(6, 6))  \n",
    "\n",
    "# Crear la visualizaciÃ³n de la matriz utilizando pcolormesh\n",
    "plt.pcolormesh(time_diff_matrix_norm, cmap='Reds')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define time factor for exploration\n",
    "time_factor = 0\n",
    "cluster_selection_epsilon=0.0\n",
    "\n",
    "# Mix both terms using time factor to weigth them\n",
    "total_distance_matrix = distance_matrix_norm + time_factor*time_diff_matrix_norm\n",
    "\n",
    "total_distance_matrix[np.abs(time_diff_matrix)>2*27] = 1e6\n",
    "total_distance_matrix[np.abs(lon_diff_matrix)>30] = 1e6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(6, 6))\n",
    "# plt.pcolormesh(total_distance_matrix, cmap='Reds')\n",
    "# plt.colorbar()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterer = hdbscan.HDBSCAN(\n",
    "    min_cluster_size=2,\n",
    "    gen_min_span_tree=True,\n",
    "    metric=\"precomputed\",\n",
    "    min_samples=2,\n",
    "    cluster_selection_method=\"leaf\",\n",
    "    cluster_selection_epsilon=cluster_selection_epsilon\n",
    ")\n",
    "clusterer.fit(total_distance_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clusterer.condensed_tree_.plot()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = cc.cm.glasbey_dark\n",
    "color_palette = sns.color_palette(cmap.colors, np.max(clusterer.labels_)+1)\n",
    "\n",
    "cluster_colors = [color_palette[x] if x >= 0\n",
    "                  else (0, 0, 0)\n",
    "                  for x in clusterer.labels_]\n",
    "\n",
    "np.sum(clusterer.labels_ == -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_quantity = len(np.unique(clusterer.labels_))\n",
    "\n",
    "len(allMag) // clusters_quantity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allMag['cluster'] = clusterer.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration = pd.Timedelta(8*365, \"d\") # In years\n",
    "t1 = np.min(allMag['Date'])\n",
    "t2 = np.max(allMag['Date'])\n",
    "\n",
    "rotation_rate = 25.38 # in days\n",
    "\n",
    "allMag['Rot_time'] = np.floor((allMag['Date']-np.min(allMag['Date'])).dt.days//rotation_rate)\n",
    "\n",
    "# allMag['BMRLongitude'] -= 360*allMag['BMRLongitude']//360\n",
    "\n",
    "ncycles = np.round((t2-t1)/duration)\n",
    "\n",
    "\n",
    "# Size definitions\n",
    "dpi = 400\n",
    "pxx = 500  # Horizontal size of each panel\n",
    "pxy = 10000  # Vertical size of each panel\n",
    "\n",
    "nph = 5     # Number of horizontal panels\n",
    "npv = 6     # Number of vertical panels \n",
    "\n",
    "# Padding\n",
    "padv  = 0  #Vertical padding in pixels\n",
    "padv2 = 0  #Vertical padding in pixels between panels\n",
    "padh  = 0 #Horizontal padding in pixels at the edge of the figure\n",
    "padh2 = 0  #Horizontal padding in pixels between panels\n",
    "\n",
    "# Figure sizes in pixels\n",
    "fszv = (npv*pxy + 2*padv + (npv-1)*padv2 )      #Vertical size of figure in pixels\n",
    "fszh = (nph*pxx + 2*padh + (nph-1)*padh2 )      #Horizontal size of figure in pixels\n",
    "\n",
    "# Conversion to relative units\n",
    "ppxx   = pxx/fszh      # Horizontal size of each panel in relative units\n",
    "ppxy   = pxy/fszv      # Vertical size of each panel in relative units\n",
    "ppadv  = padv/fszv     #Vertical padding in relative units\n",
    "ppadv2 = padv2/fszv    #Vertical padding in relative units\n",
    "ppadh  = padh/fszh     #Horizontal padding the edge of the figure in relative units\n",
    "ppadh2 = padh2/fszh    #Horizontal padding between panels in relative units\n",
    "\n",
    "\n",
    "# Combine hemispheres \n",
    "\n",
    "\n",
    "## Start Figure\n",
    "fig = plt.figure(figsize=(fszh/dpi,fszv/dpi), dpi = dpi)\n",
    "\n",
    "\n",
    "\n",
    "size = (np.sqrt(allMag['BMRFlux']/1e21))\n",
    "# size = np.abs(allMag['Tilt_rel']/5)\n",
    "\n",
    "for i in np.arange(0,18):\n",
    "\n",
    "    l1 = -45+i*5\n",
    "    l2 = -45+(i+1)*5\n",
    "        \n",
    "    ax1 = fig.add_axes([ppadh+i*ppxx, ppadv, ppxx, ppxy])\n",
    "\n",
    "    # mask = np.logical_and(allMag['Date']>=t1+n*duration, allMag['Date']<t1+(n+1)*duration)\n",
    "    mask = allMag['BMRLatitude']>=l1\n",
    "    mask = np.logical_and(mask, allMag['BMRLatitude']<l2)\n",
    "    \n",
    "    masknc =  np.logical_and(mask, clusterer.labels_ == -1)\n",
    "    mask = np.logical_and(mask, clusterer.labels_ > -1)\n",
    "    mask = np.logical_or(mask, np.in1d(clusterer.labels_, np.unique(clusterer.labels_[mask])))\n",
    "    maskah = np.logical_and(mask, allMag['AntiHale'])\n",
    "    \n",
    "    ax1.scatter(allMag.loc[mask,'BMRLongitude'], allMag.loc[mask,'Date'], s=size[mask], alpha=0.8, ec='None', c=np.array(cluster_colors)[mask])\n",
    "    ax1.scatter(allMag.loc[masknc,'BMRLongitude'], allMag.loc[masknc,'Date'], s=size[masknc], alpha=0.8, ec='None', c=np.array(cluster_colors)[masknc], marker=\"D\")\n",
    "    ax1.scatter(allMag.loc[maskah,'BMRLongitude'], allMag.loc[maskah,'Date'], s=size[maskah], alpha=0.8, ec='None', c='w', marker=\"*\", lw=0.1)\n",
    "\n",
    "    #mask = np.logical_and(mask, allMag['AntiHale'])\n",
    "    #ax1.scatter(allMag.loc[mask,'Rot_time'], allMag.loc[mask,'BMRLongitude'], s=size[mask], alpha=1,fc='k', ec='None')\n",
    "\n",
    "    # if n==0:\n",
    "    ax1.set_title(f'{l1} to {l2}')\n",
    "\n",
    "    ax1.set_ylim([np.min(allMag['Date']), np.max(allMag['Date'])])\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration = pd.Timedelta(8*365, \"d\") # In years\n",
    "t1 = np.min(allMag['Date'])\n",
    "t2 = np.max(allMag['Date'])\n",
    "\n",
    "rotation_rate = 25.38 # in days\n",
    "\n",
    "allMag['Rot_time'] = np.floor((allMag['Date']-np.min(allMag['Date'])).dt.days//rotation_rate)\n",
    "\n",
    "# allMag['BMRLongitude'] -= 360*allMag['BMRLongitude']//360\n",
    "\n",
    "ncycles = np.round((t2-t1)/duration)\n",
    "\n",
    "\n",
    "# Size definitions\n",
    "dpi = 400\n",
    "pxx = 500  # Horizontal size of each panel\n",
    "pxy = 10000  # Vertical size of each panel\n",
    "\n",
    "nph = 5     # Number of horizontal panels\n",
    "npv = 6     # Number of vertical panels \n",
    "\n",
    "# Padding\n",
    "padv  = 0  #Vertical padding in pixels\n",
    "padv2 = 0  #Vertical padding in pixels between panels\n",
    "padh  = 0 #Horizontal padding in pixels at the edge of the figure\n",
    "padh2 = 0  #Horizontal padding in pixels between panels\n",
    "\n",
    "# Figure sizes in pixels\n",
    "fszv = (npv*pxy + 2*padv + (npv-1)*padv2 )      #Vertical size of figure in pixels\n",
    "fszh = (nph*pxx + 2*padh + (nph-1)*padh2 )      #Horizontal size of figure in pixels\n",
    "\n",
    "# Conversion to relative units\n",
    "ppxx   = pxx/fszh      # Horizontal size of each panel in relative units\n",
    "ppxy   = pxy/fszv      # Vertical size of each panel in relative units\n",
    "ppadv  = padv/fszv     #Vertical padding in relative units\n",
    "ppadv2 = padv2/fszv    #Vertical padding in relative units\n",
    "ppadh  = padh/fszh     #Horizontal padding the edge of the figure in relative units\n",
    "ppadh2 = padh2/fszh    #Horizontal padding between panels in relative units\n",
    "\n",
    "\n",
    "# Combine hemispheres \n",
    "\n",
    "\n",
    "## Start Figure\n",
    "fig = plt.figure(figsize=(fszh/dpi,fszv/dpi), dpi = dpi)\n",
    "\n",
    "size = (np.sqrt(allMag['BMRFlux']/1e21))\n",
    "\n",
    "lat_lim_range = np.arange(5, 25, 5)\n",
    "lon_lim_range = np.arange(5, 25, 5)\n",
    "cluster_selection_epsilon_range = np.arange(0.02, 0.22, 0.02)\n",
    "\n",
    "for lat_lim in tqdm(lat_lim_range, position=0, total=lat_lim_range.shape[0], leave=True):\n",
    "    for lon_lim in tqdm(lon_lim_range, position=1, total=lon_lim_range.shape[0], leave=False):\n",
    "        for cluster_selection_epsilon in tqdm(cluster_selection_epsilon_range, position=2, total=cluster_selection_epsilon_range.shape[0], leave=False):\n",
    "            total_distance_matrix = distance_matrix_norm + 0*time_diff_matrix_norm\n",
    "            total_distance_matrix[np.abs(time_diff_matrix)>2*27] = 1e6        \n",
    "            total_distance_matrix[np.abs(lon_diff_matrix)>lon_lim] = 1e6\n",
    "            \n",
    "            clusterer = hdbscan.HDBSCAN(\n",
    "                min_cluster_size=2,\n",
    "                gen_min_span_tree=True,\n",
    "                metric=\"precomputed\",\n",
    "                min_samples=2,\n",
    "                cluster_selection_method=\"leaf\",\n",
    "                cluster_selection_epsilon=float(cluster_selection_epsilon)\n",
    "            )\n",
    "            clusterer.fit(total_distance_matrix)\n",
    "\n",
    "            cmap = cc.cm.glasbey_dark\n",
    "            color_palette = sns.color_palette(cmap.colors, np.max(clusterer.labels_)+1)\n",
    "\n",
    "            cluster_colors = [color_palette[x] if x >= 0\n",
    "                            else (0, 0, 0)\n",
    "                            for x in clusterer.labels_]\n",
    "            \n",
    "\n",
    "            for i in tqdm(np.arange(0,18), position=3, total=np.arange(0,18).shape[0], leave=False):\n",
    "\n",
    "                l1 = -45+i*5\n",
    "                l2 = -45+(i+1)*5\n",
    "                    \n",
    "                ax1 = fig.add_axes([ppadh+i*ppxx, ppadv, ppxx, ppxy])\n",
    "\n",
    "                # mask = np.logical_and(allMag['Date']>=t1+n*duration, allMag['Date']<t1+(n+1)*duration)\n",
    "                mask = allMag['BMRLatitude']>=l1\n",
    "                mask = np.logical_and(mask, allMag['BMRLatitude']<l2)\n",
    "                \n",
    "                masknc =  np.logical_and(mask, clusterer.labels_ == -1)\n",
    "                mask = np.logical_and(mask, clusterer.labels_ > -1)\n",
    "                mask = np.logical_or(mask, np.in1d(clusterer.labels_, np.unique(clusterer.labels_[mask])))\n",
    "                maskah = np.logical_and(mask, allMag['AntiHale'])\n",
    "                \n",
    "                ax1.scatter(allMag.loc[mask,'BMRLongitude'], allMag.loc[mask,'Date'], s=size[mask], alpha=0.8, ec='None', c=np.array(cluster_colors)[mask])\n",
    "                ax1.scatter(allMag.loc[masknc,'BMRLongitude'], allMag.loc[masknc,'Date'], s=size[masknc], alpha=0.8, ec='None', c=np.array(cluster_colors)[masknc], marker=\"D\")\n",
    "                ax1.scatter(allMag.loc[maskah,'BMRLongitude'], allMag.loc[maskah,'Date'], s=size[maskah], alpha=0.8, ec='None', c='w', marker=\"*\", lw=0.1)\n",
    "\n",
    "                #mask = np.logical_and(mask, allMag['AntiHale'])\n",
    "                #ax1.scatter(allMag.loc[mask,'Rot_time'], allMag.loc[mask,'BMRLongitude'], s=size[mask], alpha=1,fc='k', ec='None')\n",
    "\n",
    "                # if n==0:\n",
    "                ax1.set_title(f'{l1} to {l2}')\n",
    "\n",
    "                ax1.set_ylim([np.min(allMag['Date']), np.max(allMag['Date'])])\n",
    "\n",
    "            fig.savefig(f'figures/latl' + \"{:.0f}\".format(lat_lim) + 'lonl' + \"{:.0f}\".format(lon_lim) + '_ep' + \"{:.2f}\".format(cluster_selection_epsilon) + '_'+ str(i).zfill(4) + '.png', pad_inches=0, bbox_inches='tight') \n",
    "            fig.clf()                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot only window of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = pd.Timestamp('2015-04-24T00')\n",
    "t2 = pd.Timestamp('2015-08-11T00')\n",
    "\n",
    "mask = np.logical_and(allMag[f'Date']>=t1, allMag[f'Date']<=t2)\n",
    "\n",
    "allMag.loc[mask,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration = pd.Timedelta(8*365, \"d\") # In years\n",
    "\n",
    "rotation_rate = 25.38 # in days\n",
    "\n",
    "allMag['Rot_time'] = np.floor((allMag['Date']-np.min(allMag['Date'])).dt.days//rotation_rate)\n",
    "\n",
    "# allMag['BMRLongitude'] -= 360*allMag['BMRLongitude']//360\n",
    "\n",
    "ncycles = np.round((t2-t1)/duration)\n",
    "\n",
    "\n",
    "# Size definitions\n",
    "dpi = 400\n",
    "pxx = 300  # Horizontal size of each panel\n",
    "pxy = 2000  # Vertical size of each panel\n",
    "\n",
    "nph = 5     # Number of horizontal panels\n",
    "npv = 6     # Number of vertical panels \n",
    "\n",
    "# Padding\n",
    "padv  = 0  #Vertical padding in pixels\n",
    "padv2 = 0  #Vertical padding in pixels between panels\n",
    "padh  = 0 #Horizontal padding in pixels at the edge of the figure\n",
    "padh2 = 0  #Horizontal padding in pixels between panels\n",
    "\n",
    "# Figure sizes in pixels\n",
    "fszv = (npv*pxy + 2*padv + (npv-1)*padv2 )      #Vertical size of figure in pixels\n",
    "fszh = (nph*pxx + 2*padh + (nph-1)*padh2 )      #Horizontal size of figure in pixels\n",
    "\n",
    "# Conversion to relative units\n",
    "ppxx   = pxx/fszh      # Horizontal size of each panel in relative units\n",
    "ppxy   = pxy/fszv      # Vertical size of each panel in relative units\n",
    "ppadv  = padv/fszv     #Vertical padding in relative units\n",
    "ppadv2 = padv2/fszv    #Vertical padding in relative units\n",
    "ppadh  = padh/fszh     #Horizontal padding the edge of the figure in relative units\n",
    "ppadh2 = padh2/fszh    #Horizontal padding between panels in relative units\n",
    "\n",
    "\n",
    "# Combine hemispheres \n",
    "\n",
    "\n",
    "## Start Figure\n",
    "fig = plt.figure(figsize=(fszh/dpi,fszv/dpi), dpi = dpi)\n",
    "\n",
    "\n",
    "\n",
    "size = (np.sqrt(allMag['BMRFlux']/1e21))\n",
    "# size = np.abs(allMag['Tilt_rel']/5)\n",
    "\n",
    "for i in np.arange(0,18):\n",
    "\n",
    "    l1 = -45+i*5\n",
    "    l2 = -45+(i+1)*5\n",
    "        \n",
    "    ax1 = fig.add_axes([ppadh+i*ppxx, ppadv, ppxx, ppxy])\n",
    "\n",
    "    mask = np.logical_and(allMag[f'Date']>=t1, allMag[f'Date']<=t2)\n",
    "    # mask = np.logical_and(allMag['Date']>=t1+n*duration, allMag['Date']<t1+(n+1)*duration)\n",
    "    mask = np.logical_and(mask, allMag['BMRLatitude']>=l1)\n",
    "    mask = np.logical_and(mask, allMag['BMRLatitude']<l2)\n",
    "    \n",
    "    masknc =  np.logical_and(mask, clusterer.labels_ == -1)\n",
    "    mask = np.logical_and(mask, clusterer.labels_ > -1)\n",
    "    mask = np.logical_or(mask, np.in1d(clusterer.labels_, np.unique(clusterer.labels_[mask])))\n",
    "    maskah = np.logical_and(mask, allMag['AntiHale'])\n",
    "    \n",
    "    ax1.scatter(allMag.loc[mask,'BMRLongitude'], allMag.loc[mask,'Date'], s=size[mask], alpha=0.8, ec='None', c=np.array(cluster_colors)[mask])\n",
    "    ax1.scatter(allMag.loc[masknc,'BMRLongitude'], allMag.loc[masknc,'Date'], s=size[masknc], alpha=0.8, ec='None', c=np.array(cluster_colors)[masknc], marker=\"D\")\n",
    "    ax1.scatter(allMag.loc[maskah,'BMRLongitude'], allMag.loc[maskah,'Date'], s=size[maskah], alpha=0.8, ec='None', c='w', marker=\"*\", lw=0.1)\n",
    "\n",
    "    #mask = np.logical_and(mask, allMag['AntiHale'])\n",
    "    #ax1.scatter(allMag.loc[mask,'Rot_time'], allMag.loc[mask,'BMRLongitude'], s=size[mask], alpha=1,fc='k', ec='None')\n",
    "\n",
    "    # if n==0:\n",
    "    ax1.set_title(f'{l1} to {l2}')\n",
    "\n",
    "    ax1.set_ylim([t1, t2])\n",
    "\n",
    "    if i>0 and i<17:\n",
    "        ax1.set_yticklabels([])\n",
    "    \n",
    "    if i == 17:\n",
    "        ax1.yaxis.tick_right()\n",
    "        ax1.yaxis.set_label_position(\"right\")\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zarr_path = '/d0/euv/aia/preprocessed/aia_hmi_stacks_2010_2024_1d_full.zarr'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_path = '/d0/amunozj/active_longitudes'\n",
    "movie_path = f'{movie_path}/tf' + \"{:.2f}\".format(time_factor) + '_ep' + \"{:.2f}\".format(cluster_selection_epsilon) #+ 'plus'\n",
    "if not os.path.exists(movie_path):\n",
    "    os.makedirs(movie_path)\n",
    "movie_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = pd.Timestamp('2014-01-01T00')\n",
    "t2 = pd.Timestamp('2016-01-01T00')\n",
    "delta_days = 2*27\n",
    "\n",
    "t_obs_movie = t_obs.loc[np.logical_and(t_obs>=t1, t_obs<=t2)]\n",
    "closest_matches_inx = np.logical_and(t_obs>=t1, t_obs<=t2).to_numpy().nonzero()[0]\n",
    "\n",
    "shape = (int(np.round(720*2*1.8)), 1440*2)\n",
    "dpi = 200\n",
    "fig = plt.figure(figsize=[shape[1]/2/dpi*1.1,shape[0]/2/dpi*1.1], constrained_layout=True, dpi=dpi)\n",
    "spec = fig.add_gridspec(ncols=1, nrows=1, wspace=0, hspace=0)\n",
    "\n",
    "for i, test_date in tqdm(enumerate(t_obs_movie), total=t_obs_movie.shape[0]):\n",
    "\n",
    "    loaded_data = aia_hmi_stacks.aia_hmi.loc[test_date,channel, :, :].load()\n",
    "    vmax = 1500\n",
    "    vmin = -vmax\n",
    "\n",
    "    header = {}\n",
    "    for key in aia_hmi_header.keys():\n",
    "        if key != '_ARRAY_DIMENSIONS':\n",
    "            header[key] = aia_hmi_header[key][closest_matches_inx[i]]\n",
    "\n",
    "    header['wavelenth'] = 6173.0\n",
    "    header['telescop'] = 'SDO/HMI'\n",
    "    header['instrume'] = 'HMI_COMBINED'\n",
    "    hmimap = sunpy.map.Map(loaded_data.data, header)\n",
    "\n",
    "    carr_header = make_heliographic_header(hmimap.date, hmimap.observer_coordinate, shape*2, frame='carrington')\n",
    "    outmap = hmimap.reproject_to(carr_header)\n",
    "    ax = fig.add_subplot(spec[0, 0], projection=outmap)\n",
    "    outmap.plot(axes=ax, cmap=cmap, vmax=vmax, vmin=vmin)\n",
    "\n",
    "    ## Add clustered regions\n",
    "    visible_mask = np.logical_and(allMag['Date']>=test_date-pd.Timedelta(days=delta_days), allMag['Date']<=test_date+pd.Timedelta(days=delta_days))\n",
    "\n",
    "    delta_date = allMag.loc[visible_mask, 'Date'].reset_index(drop=True) - test_date\n",
    "    time_diff = ((delta_date.dt.total_seconds().values*u.s).to(u.d)).value\n",
    "    corrected_longitude = allMag.loc[visible_mask, 'BMRLongitude'].reset_index(drop=True)\n",
    "    corrected_longitude[corrected_longitude<0] = corrected_longitude[corrected_longitude<0]+360\n",
    "\n",
    "    # print(allMag.loc[visible_mask, ['BMRLatitude', 'DRot']])\n",
    "\n",
    "    corrected_longitude = allMag.loc[visible_mask, 'BMRLongitude'].reset_index(drop=True) - allMag.loc[visible_mask, 'DRot'].reset_index(drop=True) * time_diff * u.d    \n",
    "    corrected_longitude = corrected_longitude - (np.abs(corrected_longitude)//360*np.sign(corrected_longitude))*360\n",
    "    # corrected_longitude[corrected_longitude>180] = corrected_longitude[corrected_longitude>180] - 360\n",
    "    # corrected_longitude[corrected_longitude<-180] = corrected_longitude[corrected_longitude>180] + 360\n",
    "\n",
    "    cental_meridian_carr_lon = SkyCoord(0*u.deg, 0*u.deg, frame=frames.HeliographicStonyhurst).transform_to(frames.HeliographicCarrington(observer=hmimap.observer_coordinate, obstime=hmimap.date)).lon.value\n",
    "    # print('central_lon', cental_meridian_carr_lon, i)\n",
    "\n",
    "    for n, row in allMag.loc[visible_mask].reset_index(drop=True).iterrows():\n",
    "\n",
    "        delta_lon = corrected_longitude[n] - cental_meridian_carr_lon\n",
    "        if delta_lon < -180:\n",
    "            delta_lon = 360+delta_lon\n",
    "        if delta_lon > 180:\n",
    "            delta_lon = -(360-delta_lon)\n",
    "\n",
    "        bmr_center = SkyCoord(lat=row['BMRLatitude']*u.deg, lon=corrected_longitude[n]*u.deg, frame=HeliographicCarrington, obstime=hmimap.date, observer=hmimap.observer_coordinate)\n",
    "        point_in_hpc = bmr_center.transform_to(hmimap.coordinate_frame)\n",
    "\n",
    "        if row['cluster'] > -1:\n",
    "\n",
    "            if np.abs(delta_lon)>=90 or np.abs(time_diff)[n]>10:\n",
    "                alpha = (delta_days - (np.abs(time_diff[n])-10))/(delta_days)*0.4\n",
    "                alpha = np.max([alpha,0]) + 0.1\n",
    "\n",
    "                if time_diff[n] < 0:\n",
    "                    ax.plot_coord(point_in_hpc, marker=\"v\", ms=15, alpha=alpha, c=np.array(cluster_colors)[visible_mask][n], markeredgecolor='None')\n",
    "                else:\n",
    "                    ax.plot_coord(point_in_hpc, marker=\"^\", ms=15, alpha=alpha, c=np.array(cluster_colors)[visible_mask][n], markeredgecolor='None')\n",
    "\n",
    "            if np.abs(delta_lon)<=90 and np.abs(time_diff)[n]<10:\n",
    "                ax.plot_coord(point_in_hpc, marker=\"o\", ms=15, alpha=0.6, c=np.array(cluster_colors)[visible_mask][n], markeredgecolor='k')\n",
    "\n",
    "        else:\n",
    "            if np.abs(delta_lon)<=90 and np.abs(time_diff)[n]<10:\n",
    "                ax.plot_coord(point_in_hpc, marker=\"s\", ms=15, alpha=1, markerfacecolor='None', markeredgecolor='k')\n",
    "\n",
    "    ax_lim = ax.get_ylim()\n",
    "    ax1 = ax_lim[0] + (ax_lim[1]-ax_lim[0])*(50/180)\n",
    "    ax2 = ax_lim[0] + (ax_lim[1]-ax_lim[0])*(130/180)\n",
    "    ax.set_ylim(ax1,ax2)\n",
    "\n",
    "    fig.savefig(f'{movie_path}/tf' + \"{:.2f}\".format(time_factor) + '_ep' + \"{:.2f}\".format(cluster_selection_epsilon) + '_'+ str(i).zfill(4) + '.png', pad_inches=0, bbox_inches='tight') \n",
    "    fig.clf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr = []\n",
    "for i, test_date in tqdm(enumerate(t_obs_movie), total=t_obs_movie.shape[0]):\n",
    "    cental_meridian_carr_lon = SkyCoord(0*u.deg, 0*u.deg, frame=frames.HeliographicStonyhurst).transform_to(frames.HeliographicCarrington(observer='earth', obstime=test_date)).lon.value\n",
    "    cr.append(cental_meridian_carr_lon)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_numpy = t_obs.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_dif = ((t_obs.iloc[1:].reset_index(drop=True) - t_obs.iloc[0:-1].reset_index(drop=True)).dt.total_seconds().values*u.s).to(u.d).value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(t_obs[(t_dif>1.5).nonzero()[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(t_dif>1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "465bc43bf4cbae58c142e3527ff2b05702dd810bc8ebc4f627e0af6c067b87a4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
